---
title: "Modeling The Freshening Power of the Hop"
subtitle: "Version 0.21 1/27/19"
output:
     pdf_document:
         latex_engine: xelatex
---

> merge from 
ASBC2019_lrcPart1_model1 tidy transform_ujbc_a_1469081_sm5496.txt.v05_add exptOLD_thisWORKS.RMD and 
ASBC2019_lrcPart2_model1_ujbc_a_1469081_sm5496.txt.v12b.RMD

> ActionItem:  reforat from scratch following   https://labrtorian.com/tag/cran/
<https://labrtorian.com/tag/cran/>


*Step1:  Open this .RMD file in R Studio and click the "Preview" button above.  A formatted version should pop up in a browser window.  IF not, troubleshoot that!*

# outline


#Intro
This is primarily an excercise in data wrangling, modeling, and markdown formatting using R Studio.  In that context, this analysis is a *preliminary* attempt to develop a metric for *Hop Freshening Power* (syn. 'dryhop creep', 'ABV creep', 'dry-hop creep') and to model this aspect of the process of making dry-hopped beers. If you care what this means in a beer and brewing context, bear in mind that several research groups the Shellhammer group at Oregon State Universityhas done extensive work . 

In contrast to much of the recent work to characterize the molecular mechanisms at play, the data used for this work are relatively 'simple' whole-system factors and endpoints:  a certain amount of hops are added to beers under various conditions, allowed to react for various amounts of time, then the resulting beers were tested for alcohol content (using Anton Paar DMA4500 Beer Alcolyzer) to produce the data we are using in this exercise.  

##load libraries:
```{r package.load, results='asis', echo=FALSE, include=FALSE} 
#.rs.restartR()  # restart R 
sessionInfo()

#data wrangling
#install.packages("dplyr")  # dplyr "data plyer"  
library(dplyr)

#formating tables
#library(xtable)
library(knitr)
library(flextable)  # to make fancy tables
library(magrittr)   # allows piping (%>%) directly into graphics functions
library(kableExtra)  ## kableExtra for fancy tables with maths

#text processing
#library(stringi)
#library(tidytext)
#library(yarrr)

#graphics
library(ggplot2)
#library(ggvis)
library(gridExtra)  # for grid.arrange in R markdown


#modeling
#library(nlme)    # Nonlinear Mixed-Effects Models
library(memisc)  # compare models

#others
#library(qcc)
library(psych)   # for pairs.panels
library(caret)   # to 'dummify' factor data
#library(lubridate) # lubridate for dates/times in general
#library(chron)     #  chron for converting fractional days to AM/PM/24HR/etc time formats
library(officer)  ## manipulate/create MSword and MSpowerpoint files; used here in 'vanity tables' to use Greek symbols
sessionInfo()
```


Have a look at the data:
```{r}
mydata <-read.csv("ujbc_a_1469081_sm5496.txt")  ## SPECIFY filename
# various ways to select columns by data type
#mydata %>% select_if(negate(is.numeric)) %>% names() ## NOT nonnumericcols (NOTE: integers!)
#mydata %>% select_if(funs(is.integer(.))) %>% names() ## integers (note funs() wrapper)
#mydata %>% select_if(~ !(is.integer(.x)) | is.numeric(.x)) %>% names() ## num OR int
#mydata %>% select_if(~ !(is.integer(.)) | is.numeric(.)) %>% names() ## num OR int
#mydata %>% select_if((is.factor)) %>% names() ## factors
#mydata %>% select_if(is.numeric) %>% names() ## numeric (NOTE: integers included!)
#mydata %>% select_if(is.character()) %>% names() ## characters
names(mydata)
```

```{r}
table(mydata$Hop_type)
```

Several different columns in the original dataset were evaluated as specific endpoints (Y-values) to model the *freshening power of the hop*.  Through that, two errors in the original approach led to overly-complicated (and, of course, mostly worthless :) models.  a focus on ABV rather than ABW, and the notion that the metric was a property of the hops, rather than a property of the entire system.  Metrics equating the increase in ethanol (FPH_EtOH) or carbon dioxide (FPH_CO2) produced to the amount of hops added (all in g/100mL), relative to the same system with no dry-hopping.  The metric was developed through attempts to correct for the exact amount of hops added (w/v) in each experiment.

Regardless how we measure this phenomenon, through experience in brewing we know that:

Endpoints of dryhopping
* flavor impact (always)
* impact on visual/presentation (sometimes)
* *ethanol increase* accompanied by decrease in specific gravity (sometimes)
* CO2 increase (sometimes)
* diacetyl/VDK increase (sometimes)
* and so on...

Focusing on *ethanol increase as the endpoint*, we know these to be *relevant factors* (and comments as they relate to these data):
* variety of hops (five different varieties)
* presence of live yeast (true in all cases for these data)
* temp.C = temperature during dryhopping (mostly warm, with a few in the cold)
* amount of contact time between hops and beer (up to 7 weeks)

We will ultimately widdle down the input data to only include Centennial hops and evaluate several functions that equate ethanol and **calculated CO2** increases separately as functions of contact time. 

#table of useful models with examples...


It should be *noted that CO2 is somewhat toxic to yeast, but this probably had minimal effect on these data because the experiments were carried out in vented (crimped foil) containers.  Had these reactions carried out in closed containers, it is unlikely they would have proceeded in this manner.  Some of the calculated CO2 concentrations  below would presumably impact almost any yeast-catalyzed reaction.

In most cases the variables used below to model hop freshening power are *calculations* based on the original data. The process of creating new variables from existing variables is known as *data transformation*, one of Wickham's four iterations of data analysis.  The process of transforming the original data was detailed in a [preceeding Notebook](reference FPH tidy and trasform!!) and presented below as a single code chunk.

For more details on this dataset see the [manuscript](https://www.tandfonline.com/doi/full/10.1080/03610470.2018.1469081?scroll=top&needAccess=true "Kirkendall2018").  Undoubtedly, any 'complete' model of *Hop Freshening Power* will incorporate molecular information exemplified by the OSU researchers (e.g. production of glucose and maltose) and will certainly involve some yeast-related factors.

* please send complaints and corrections to luke.chadwick@gmail.com!
* Data are from the file "ujbc_a_1469081_sm5496.txt" (supplementary data from Jacob A. Kirkendall, Carter A. Mitchell & Lucas R. Chadwick (2018): The Freshening Power of Centennial Hops, *Journal of the American Society of Brewing Chemists* Volume 76, Issue 3, Pages 178-184 (**2018**) DOI: 10.1080/03610470.2018.1469081* available from <https://www.tandfonline.com/doi/full/10.1080/03610470.2018.1469081?scroll=top&needAccess=true>

* [Wickham's four pillars of data analysis:](https://r4ds.had.co.nz/ "Grolemund and Wickham's R for Data Science")
    + tidy
        - transform
        - visualize
        - *model*

* [*"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."*](http://www.datagovernance.com/quotes/knowledge-quotes/ "Clifford Stoll")

* [this is not a] stats class
    + descriptive statistics
    + inferential statistics
    + *modeling*   --> *the journey as the destination*


## FPHcalc in a single chunk:  chunk_tidytransform
```{r chunk_tidytransform, include=FALSE}
rm(list = ls()) # clear workspace
mydata <-read.csv("ujbc_a_1469081_sm5496.txt",stringsAsFactors = FALSE)  ## SPECIFY filename

## create new variables (*.POSIXct, timeofaddition, daysonhops, hops_g_100mL, pounds_bbl, variety, harvestyear,ox)
### note: this is a base R data wrangling exercise! in general it's best to use lubridate package for date/timestamps! 

## can do one at a time (here we're creating new columns in POSIXct format, based on the particular date format used in the source data (ujbc_a_1469081_sm5496.txt; see ?as.POSIXct):
#x_brew_date.POSIXct<- as.POSIXct(mydata$brew_date, format = "%m/%d/%Y") # as a standalone vector (USELESS here), or:
#mydata$brew_date.POSIXct <-as.POSIXct(mydata$brew_date, format = "%m/%d/%Y")  # as a "new column" in our dataframe
  
## or, we can take advantage of the pattern that of our (character) date/time columns have the string "date" in the headername.  First make character vector of all column names containing string "date":
#datecols<- dput(names(select(mydata, matches("date"))))  ## headers containing string "date"

dput(names(mydata))

datecols<- c("brew_date", "sample_collection_date", "dryhop_date", "Test_Date")
## FORLOOP
# this forloop will (attempt to) convert datecols (define above) into POSIXct format (R datetime format).  In general they say it's  ### best to avoid forloops ### use functions from lubridate/etc packages with specific tools for the task at hand)!! ###
for (icol in datecols) {
  newcol = paste0(icol,".POSIXct")
  print(newcol)
  mydata[, newcol] = as.POSIXct(mydata[, icol],format = "%m/%d/%Y") ###  CREATE NEW columns with POSIXct   
#  mydata[, newcol] = as.POSIXct(as.numeric(mydata[, icol])  * (60*60*24), origin="1899-12-30") ###  microsoft times
}

## create timeofaddition, daysonhops, hops_g_100mL, pounds_bbl variables with dplyr "mutate"
mydata<- mydata %>% 
  mutate(timeofaddition = as.numeric(difftime(dryhop_date.POSIXct,brew_date.POSIXct)),
         daysonhops = as.numeric(difftime(Test_Date.POSIXct,dryhop_date.POSIXct)),
         hops_g_100mL = (mg_hops/volume_mL)/10,
         pounds_bbl = (mg_hops/volume_mL)*117/454
         )

mydata$OX<-grepl("OX", mydata$Hop_type)           ##  create logical "OX" column
mydata$rouse<-grepl("rouse", mydata$special_group)##  create logical "rouse" column
mydata$Grind<-grepl("Grind", mydata$Hop_type)     ##  create logical column
mydata$Cone<-grepl("Cone", mydata$Hop_type)       ##  create logical column
mydata$harvest2014<-grepl("14", mydata$Hop_type)  ##  create logical column
mydata$harvest2015<-grepl("15", mydata$Hop_type)  ##  create logical column
mydata$harvest2017<-grepl("17", mydata$Hop_type)  ##  create logical column
## ifelse statement for harvestyear (if neither 2014 nor 2015 nor 2017, then 2016)
mydata$harvestYear <- ifelse(
  mydata$harvest2014==TRUE, 2014,
  ifelse(mydata$harvest2015==TRUE, 2015, 
         ifelse(mydata$harvest2017==TRUE, 2017, 2016)))
## ifelse statement for form of hops (if neither cone nor ground nor NH, then pellet) 
mydata$form_of_hops <- ifelse(
  mydata$Cone==TRUE, "cone",
  ifelse(mydata$Grind==TRUE, "ground",
         ifelse(mydata$Hop_type=="NH", "NH", "pellet")))

## ifelse statement for temperature greater or less than 10 
mydata$DH_temp <- ifelse(
  mydata$temp.C<10, "cold",
  ifelse(mydata$temp.C>10, "warm", "something else"))

## create "variety" column starting with "Hop_type" then stripping away all the non-variety information
mydata$variety<-mydata$Hop_type
mydata$variety<- gsub("17","", mydata$variety)
mydata$variety<- gsub("16","", mydata$variety)
mydata$variety<- gsub("15","", mydata$variety)
mydata$variety<- gsub("14","", mydata$variety)
mydata$variety<- gsub("OX","", mydata$variety)
mydata$variety<- gsub("Grind","", mydata$variety)
mydata$variety<- gsub("Cone","", mydata$variety)
mydata$variety<- gsub(" ","", mydata$variety)

## create "EXPTnew" variable to account for beer not being end-fermented when time-series (expt 2A) commenced
mydata<- mydata %>% mutate(EXPTnew=paste0("group",expt, substr(special_group, 1,2),as.character(rouse)))
# clean it up by removing "NA" and any spaces due to canarycode bug
mydata$EXPTnew <- gsub(" ","", mydata$EXPTnew)  ## remove any spaces
mydata$EXPTnew <- gsub("NA","", mydata$EXPTnew) ## remove "NA"

## rearrange columns (experimental factors on the left, then measurements, followed by calculations and finally all the date columns on the right):
mydata <- mydata %>% 
  dplyr::select(sample_id,expt, EXPTnew, hop, BINhop, variety, OX, harvestYear, form_of_hops, rouse, daysonhops, timeofaddition, DH_temp, temp.C, hops_g_100mL, pounds_bbl,
         ABV, ABW, OE, Er, Ea, SG, RDF, ADF, Calories, 
         dhop_day, contact_days, REF_NH, ABV_increase, 
         brew_date.POSIXct, sample_collection_date.POSIXct, dryhop_date.POSIXct,Test_Date.POSIXct)
## remove ".POSIXct" suffix.  Leaving it as-is will only add to confusion if/when these data are saved and re-imported (and become 'character' format!)
colnames(mydata) = gsub(".POSIXct", "", colnames(mydata))

#compute baseline ABW for each EXPTnew group
meanABW.REF_NH<- mydata %>% 
  group_by(EXPTnew) %>%
  filter(hop=="NH") %>%
  summarise(ABW.REF_NH=mean(ABW))

## compute mean increase in ABW relative to meanABW.REF_NH (unhopped samples in same EXPTnew group), and normalize this relative to the exact amount of hops added
## using objects created above...
## first join our data with mean ABV for unhopped samples in given experiment (meanABW.REF_NH; calculated above)

FPHcalc<- left_join(mydata, meanABW.REF_NH, by="EXPTnew")

## now calculate ABW_increase by subtracting each individual ABW measurement from meanABW.REF_NH:
FPHcalc$ABW_increase <- FPHcalc$ABW - FPHcalc$ABW.REF_NH

## the control samples have served their purpose, now remove them from dataset. The following calculations are only meaningful for dry-hopped samples.  
FPHcalc<- FPHcalc %>% filter(hop=="DH")

## compute corresponding CO2 production following Bamforth (describing Balling equation) "...more realistically, the ethanol yield is more like 0.46 g and carbon dioxide 0.44 g from 1 g sugar"  (p. 137 in Brewing Materials and Processes: A Practical Approach to Beer Excellence, Edited by Charles Bamforth Academic Press, 2016)
FPHcalc$calcCO2_increase <- FPHcalc$ABW_increase*(0.44/0.46)
##convert calcCO2_increase (in g/100mL) to calculated CO2 volumes added
## g/L = 10* g/100mL
## The conversion factor from volumes of CO2 to CO2 by weight (g/L) is 1.96. For example: 2.5 volumes x 1.96 = 4.9 g/l.
FPHcalc$calcCO2vols_increase <- FPHcalc$calcCO2_increase*10/1.96

## and define "FPH" as amount produced per % dry-hops added (in g/100mL):
FPHcalc$FPH_EtOH = FPHcalc$ABW_increase/FPHcalc$hops_g_100mL
FPHcalc$FPH_CO2 = FPHcalc$calcCO2_increase/FPHcalc$hops_g_100mL

## and save the transformed data to csv:
write.csv(FPHcalc,"FPHcalc.csv", row.names = FALSE)
```

## data summary
```{r NOTvanitytable, echo=FALSE}
FPHcalc <- read.csv("FPHcalc.csv", stringsAsFactors = TRUE)

df<- FPHcalc %>% group_by(EXPTnew) %>%
  summarise_at(vars(hops_g_100mL,pounds_bbl, ABW_increase,FPH_EtOH, FPH_CO2, calcCO2vols_increase),funs(mean)) %>%
  arrange(desc(FPH_EtOH)) 
df
```

#modeling Overview
Observing the impacts of dryhopping in the presence of live yeast has led many brewing professionals to understand that FPH is a function of many of the variables above including hop variety,form_of_hops,harvestYear,OX,DH_temp,daysonhops,rouse,pounds_bbl.... Many have intuitively created a model in their heads (without necessarily thinking of it as such) and skillfully adjust process when necessary to account for this phenomenon.  In linear modeling, our function will take on the form:
$FPH =  intercept + \beta_{1}X_{1} + \beta_{2}X_{2} + ... + \beta_{n}X_{n}$ where $\beta$ values are what we're attempting to derive in this modeling exercise, and X values are (collectively) a particular set of conditions.

>> ActionItem:  add link to modeling overview


# vector~vector scatter plots
```{r regression.1}

FPHcalc <- read.csv("FPHcalc.csv", stringsAsFactors = TRUE)

df<- FPHcalc
p1<- ggplot(df, aes(y=SG,x=OE)) + geom_point(size=2) + labs(tag="lm1")
p2<- ggplot(df, aes(y=SG,x=ADF)) + geom_point(size=2) + labs(tag="lm2")
p3<- ggplot(df, aes(y=SG,x=ABW)) + geom_point(size=2) + labs(tag="lm3")
p4<- ggplot(df, aes(y=SG,x=Ea)) + geom_point(size=2) + labs(tag="lm4")
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

# linear models 1 (create models)
```{r}
df<-FPHcalc
Y <- df$SG
x1 <- df$OE
x2 <- df$ADF
x3 <- df$ABW
x4 <- df$Ea

lm1<-lm(Y~x1)
lm2<-lm(Y~x2)
lm3<-lm(Y~x3)
lm4<-lm(Y~x4)
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(Y~x1)
abline(lm1)
plot(Y~x2)
abline(lm2)
plot(Y~x3)
abline(lm3)
plot(Y~x4)
abline(lm4)
```

# linear models 2 (view residual plots)
```{r}
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(lm1$residuals)
plot(lm2$residuals)
plot(lm3$residuals)
plot(lm4$residuals)
#summary(lm4)
```


# compare linear models with mtable function in package memisc
```{r}
mtable1234 <- mtable("Model 1"=lm1,"Model 2"=lm2,"Model 3"=lm3, "Model 4"=lm4,
                    summary.stats=c("sigma","R-squared","F","p","N"),show.eqnames=T)

mtable1234b <- relabel(mtable1234,
                      "(Intercept)" = "Constant",
                      OE = "OE = Original Extract (g/100mL)",
                      ADF = "ADF = Apparent Degree of Fermentation (%)",
                      ABW = "ABW = Ethanol (w/w)",
                      Er = "Er = Residual Extract (g/100mL)"
                      )
mtable1234
#show_html(mtable1234b)
```


# vector~vector*vector plots
```{r regression.2}
df <-FPHcalc
p1<- ggplot(df, aes(y=OE,x=ADF, color=contact_days)) + geom_point(size=2)
p2<- ggplot(df, aes(y=OE,x=SG, color=contact_days)) + geom_point(size=2)
p3<- ggplot(df, aes(y=OE,x=ABV, color=rouse)) + geom_point(size=2)
p4<- ggplot(df, aes(y=OE,x=ABW, color=expt)) + geom_point(size=2)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```



# x~y*(4 vectors) by color
```{r regression.4plot.color}
df <- FPHcalc
x<- df$ABW
y<- df$FPH_EtOH

p1<- ggplot(df, aes(x,y, color=form_of_hops)) + geom_point(size=2)
p2<- ggplot(df, aes(x,y, color=brew_date)) + geom_point(size=2)
p3<- ggplot(df, aes(x,y, color=rouse)) + geom_point(size=2)
p4<- ggplot(df, aes(x,y, color=pounds_bbl)) + geom_point(size=2)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

> !! include brew_date in model 

# x~y*vector by shape
```{r regression.4plot.shape}
df <- FPHcalc
x<- df$ABW
y<- df$FPH_EtOH

p1<- ggplot(df, aes(x,y, color=form_of_hops)) + geom_point(size=2) 
p2<- ggplot(df, aes(x,y, color=DH_temp)) + geom_point(size=2)
p3<- ggplot(df, aes(x,y, color=-rouse)) + geom_point(size=2)
p4<- ggplot(df, aes(x,y, shape=variety)) + geom_point(size=2)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

#Amunategui "Using Correlations To Understand Your Data"
```{r Amunategui}
mydata<-FPHcalc %>% dplyr::select(variety,form_of_hops,pounds_bbl,rouse,daysonhops,DH_temp,ABW,SG,OE,ADF,RDF,calcCO2vols_increase,FPH_CO2, FPH_EtOH)  ## last one is 100% in j

## note use of "dplyr::select" because one of these packages is conflicting with dplyr commands :()

## following  Manuel Amunategui  https://www.youtube.com/watch?v=igPQ-pI8Bjo
## Using Correlations To Understand Your Data: Machine Learning With R 
##functions for flattenSquareMatrix
cor.prob <- function (X, dfr=nrow(X) -2) {
  R<- cor(X, use="pairwise.complete.obs")
  above<- row(R) < col(R)
  r2 <- R[above]^2
  Fstat<- r2 * dfr/(1-r2)
  R[above] <- 1- pf(Fstat, 1, dfr)
  R[row(R) == col(R)] <- NA
  R
}
flattenSquareMatrix <- function(m) {
  if( (class(m) != "matrix") | (nrow(m)!=ncol(m))) stop("Must be a square matrix.")
  if(!identical(rownames(m), colnames(m))) stop("Row and column names must be equal.")
  ut <- upper.tri(m)
  data.frame(i = rownames(m)[row(m)[ut]],
             j = rownames(m)[col(m)[ut]],
             cor=t(m)[ut],
             p=m[ut])
}

## library(caret) to dummify everything (turn all characters&factors into columns;  ignores numbers and integers)
dmy<- dummyVars(" ~ .",data = mydata)
mydummifieddata<- data.frame(predict(dmy, newdata = mydata))
corMat = cor(mydummifieddata)
corMasterList<- flattenSquareMatrix(cor.prob(mydummifieddata)) ## list of all correlations
## order by strength of correlation
corlist<- corMasterList[order(-abs(corMasterList$cor)),]  
write.csv(corlist,paste0("FLAT correlation matrix_.csv"))
corlist <- corlist %>% dplyr::filter(j=="FPH_EtOH")   ## filter specific endpoint
head(corlist,50)
```

# pairs.panels correlation matrix from library(psych)
```{r}
## specify interesting variables:  
interestingvariables<-c("ABW", "pounds_bbl", "daysonhops", "calcCO2vols_increase") 
pairs.panels(mydummifieddata[c(interestingvariables, "FPH_EtOH")])
```


# compare linear models
```{r}
df <- FPHcalc
lm1<-lm(FPH_EtOH~daysonhops, data=df)
lm2<-lm(FPH_EtOH~daysonhops*form_of_hops, data=df)
lm3<-lm(FPH_EtOH~daysonhops*rouse, data=df)
lm4<-lm(FPH_EtOH~daysonhops*form_of_hops*rouse, data=df)

mtable1234 <- mtable("Model 1"=lm1,"Model 2"=lm2,"Model 3"=lm3, "Model 4"=lm4,
                    summary.stats=c("sigma","R-squared","F","p","N"),show.eqnames=T)
mtable1234b <- relabel(mtable1234,
                      "(Intercept)" = "Constant",
                      SG = "Specific Gravity",
                      ABW = "ABW = Ethanol (w/w)",
                      Er = "Er = Residual Extract (g/100mL)"
                      )
mtable1234
#show_html(mtable1234b)
```


#modeling FPH
To make our model of the *Freshening Power of* **Centennial** *Hops*, we will narrow down the dataset as follows:
*filter only include variety=="CENT"
*remove the "rouse" samples (rousing did not significantly impact FPH)
*create some "anchor rows" for time zero, to tell our model that there was zero ABW increase the moment hops were added. Even if we did have time zero data (we don't in most cases), instrument noise would likely cause extreme values in calculations and be problematic for modeling purposes.

```{r}
#time zero rows "anchor rows"
## since we know for certain that at time zero, the true dry-hop induced ethanol increase is zero.  Some time-zero rows we make "by hand" will reflect this reality much better than using real data that in this case.  (our real data at time zero is mostly instrument noise).
## we'll make three identical rows per
unique_rows <- !duplicated(FPHcalc[c("variety","OX","harvestYear", "form_of_hops", "DH_temp")])  ## identify unique combinations
df <- FPHcalc[unique_rows,]     ## subset unique combinations
df$daysonhops<- 0
df$timeofaddition<- 0
df$ABV<- 0
df$ABW<- 0
df$OE<- 0
df$Er<- 0
df$Ea<- 0
df$SG<- 0
df$RDF<- 0
df$ADF<- 0
df$dhop_day<- 0
df$contact_days<- 0
df$ABV_increase<- 0
df$ABW.REF_NH<- 0
df$ABW_increase<- 0
df$FPH_EtOH<- 0
df$FPH_CO2<- 0
timezerorows<-rbind(df,df)    ### duplicates
timezerorows<-rbind(timezerorows,df)  ### triplicates
df2<-rbind(FPHcalc,timezerorows)  ### triplicates
```


# narrow down dataset and compare linear models
```{r}

## narrow down dataset
df<- df2 %>% dplyr::filter(variety=="CENT"&rouse==FALSE&DH_temp=="warm")      # filter rows

df<- df %>% dplyr::select(FPH_EtOH,daysonhops,brew_date,form_of_hops)  # select columns


#compare models

lm1<-lm(FPH_EtOH~daysonhops, data=df)
lm2<-lm(FPH_EtOH~daysonhops*form_of_hops, data=df)
lm3<-lm(FPH_EtOH~daysonhops*brew_date, data=df)
lm4<-lm(FPH_EtOH~daysonhops*brew_date*form_of_hops, data=df)

mtable1234 <- mtable("Model 1"=lm1,"Model 2"=lm2,"Model 3"=lm3, "Model 4"=lm4,
                    summary.stats=c("sigma","R-squared","F","p","N"),show.eqnames=T)
mtable1234b <- relabel(mtable1234,
                      "(Intercept)" = "Constant",
                      SG = "Specific Gravity",
                      ABW = "ABW = Ethanol (w/w)",
                      Er = "Er = Residual Extract (g/100mL)"
                      )
mtable1234
#show_html(mtable1234b)
```

#The R Book (Crawley) Table 20.1: nonlinear functions useful in biology   
Table 20.1. [Useful non-linear functions](https://www.cs.upc.edu/~robert/teaching/estadistica/TheRBook.pdf "Michael J. Crawley.  The R book.  p. 738") EXPANDED:



| Function Class | name | equation | example code |example applications|
|:----------|:-----:|:-------|:-----|:-----|
| **Asymptotic functions**|Michaelis–Menten|$y =\frac{ax}{1+bx}$|nls(bone~a*age/(1+b*age),start=list(a=8,b=0.08))) | enzyme reactions |
| | | | nls(rate~SSmicmen(conc,a,b)) | tbd|
| |2-parameter asymptotic exponential | $y = a(1 − e^{−bx} )$ |nls(bone~a*(1-exp(-c*age)),start=list(a=120,c=0.064)) | tbd |
| |3-parameter asymptotic exponential | $y = a − be^{−cx}$ | nls(bone~a-b*exp(-c*age),start=list(a=120,b=110,c=0.064)) | tbd |
| | | | nls(bone~SSasymp(age,a,b,c)) | tbd |
| | | | nls(density ~ SSlogis(log(concentration), a, b, c)) | tbd |
|**S-shaped functions** |2-parameter logistic |$y = \frac{e^{a+bx}}{1 + e^{a+bx}}$ | | tbd |
| | 3-parameter logistic | $y = \frac{a}{1 + be^{−cx}}$ | | tbd |
| | 4-parameter logistic | $y = a + \frac{b-a}{1 + e^{(c−x)/d}}$ | nls(weight~SSfpl(Time, a, b, c, d)) | tbd |
| | Weibull | $y = a − be^{−(cx^d)}$ | nls(weight ~ SSweibull(time, Asym, Drop, lrc, pwr)) | tbd |
| | Gompertz | $y = ae^{−be^{−cx}}$ | | tbd |
| **Humped curves** | Ricker curve | $y = axe^{−bx}$ | | tbd |
| | First-order compartment | $y = k exp(−exp(a)x) − exp(−exp(b)x)$ | nls(conc~SSfol(Dose, Time, a, b, c)) | tbd |
| | Bell-shaped | $y = a exp(−ABS(bx)^2)$ | | tbd |
| | Biexponential | $y = ae^{bx} − ce^{−dx}$  | | tbd |



```{r}
sessionInfo()
```


