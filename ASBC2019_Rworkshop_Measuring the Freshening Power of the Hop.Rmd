---
title: "R Notebook: Measuring the Freshening Power of the Hop"
output: html_notebook
---


*Step1:  Open this .RMD file in R Studio and click the "Preview" button above.  A formatted version should pop up in a browser window.  IF not, troubleshoot that!*

> When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

> The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

> Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

> Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.


# manual outline

1. Housekeeping
    1. *SET WORKING DIRECTORY* 
    1. this **R Markdown (.RMD)** document was created using R Studio
        1. plain text
        1. "Reproducible Research" Movement
    1. ***R*** from <https://www.r-project.org/>
    1. ***R Studio*** from <https://www.rstudio.com/products/rstudio/download/>
    1. Environment tab (Rstudio)
    1. Files/Plots/Packages/Help/Viewer  tab (Rstudio)
    1. Preview/view as HTML  (R Markdown in Rstudio)
    1. Outline tab (R Markdown in Rstudio)
    
* Intro
    + Statement of Problem
    + Overview of Experimental Data
    + Measuring the Freshening Power of the Hop (relative to non-dryhopped controls)
    + *calculated metrics*
        - $\Delta$ABV 
        - $\Delta$ABW
        - $\Delta{calculated}$CO$_2$
        - $\Delta$ &deg;plato
        - $\Delta$SG$^{20/20}$
        - fold-increase ethanol from hop addition (in $\frac{pounds}{bbl}$ and wt% or $\frac{grams}{100 mL}$)
        - fold-increase CO$_2$ from hop addition (in g/L and CO$_2$ volumes)
* Load Libraries
* Data Import, Tidy and Transform
* Data Visualization
    + scatter plots
    + scatter plots with added dimensions
* Modeling overview
    + linear regression
    + residuals
* Modeling FPH


# intro

* [*"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."*](http://www.datagovernance.com/quotes/knowledge-quotes/ "Clifford Stoll")
* [Wickham's four pillars of data analysis:](https://r4ds.had.co.nz/ "Grolemund and Wickham's R for Data Science")
    * tidy
    * transform
    * visualize
    * model

ascii font/art from <http://www.network-science.de/ascii/>
```{r echo=TRUE}
#                       __  .__    .___      
#                     _/  |_|__| __| _/__.__.
#                     \   __\  |/ __ <   |  |
#                      |  | |  / /_/ |\___  |
#                      |__| |__\____ |/ ____|
#                                   \/\/     
#                                    \/
#                                     |
#                                     |
#                                     |
#              _                     /\               
#             | |_ _ _ __ _ _ _  ___/ _|___ _ _ _ __  
#             |  _| '_/ _` | ' \(_-<  _/ _ \ '_| '  \ 
#              \__|_| \__,_|_||_/__/_| \___/_| |_|_|_|
#                         /                      \
#                        /                        \
#                       /                          \
#                      /                            \
#          _          /   _ _                        \    _     _ 
#     __ _(_)____  _ __ _| (_)______        _ __  ___  __| |___| |
#     \ V / (_-< || / _` | | |_ / -_) _____| '  \/ _ \/ _` / -_) |
#      \_/|_/__/\_,_\__,_|_|_/__\___|      |_|_|_\___/\__,_\___|_|
```

This is primarily an excercise in data wrangling (tidy+transform) and markdown formatting using R Studio.  In that context, this analysis is a *preliminary* attempt to develop practical metrics for *Hop Freshening Power* (syn. 'dryhop creep', 'ABV creep', 'dry-hop creep') and to model this aspect of the warm-dryhopping process. 

## Statement of Problem
The warm-dryhopping process can profoundly impact the body, alcohol and vicinal diketone content of the beer.  A common metric for this phenomenon has not been established.

## Overview of Experimental Data
Through experience in brewing we know that **endpoints** of dryhopping include:

* flavor impact (always)
* impact on visual/presentation (sometimes)
* *ethanol increase* accompanied by decrease in specific gravity (sometimes)
* CO2 increase (sometimes)
* diacetyl/VDK increase (sometimes)
* and so on...

Experiments were carried out where 

1. multiple replicate 250-mL samples were collected into 12oz amber bottles
    1. the samples were randomized into groups of three
        * some groups were dry-hopped (treatment) at roughly 1.0 pounds/bbl
        * some groups were not (control)
2. all were hand-crimped with foil, stored for various times (mostly at room temp, a few in the cold), then tested on an Anton Paar DMA4500/Alcolyzer classic
        
Focusing on *ethanol increase as the endpoint*, we know these to be **relevant factors**:

* variety of hops (five different varieties)
* presence of live yeast (true in all cases for these data)
* temp.C = temperature during dryhopping (mostly warm, with a few in the cold)
* amount of contact time between hops and beer (up to 7 weeks)

*For more details on this dataset see the [manuscript](https://www.tandfonline.com/doi/full/10.1080/03610470.2018.1469081?scroll=top&needAccess=true "Kirkendall2018").  
* please send complaints and corrections to luke.chadwick@gmail.com!
* Data are from the file "ujbc_a_1469081_sm5496.txt" (supplementary data from Jacob A. Kirkendall, Carter A. Mitchell & Lucas R. Chadwick (2018): The Freshening Power of Centennial Hops, *Journal of the American Society of Brewing Chemists* Volume 76, Issue 3, Pages 178-184 (**2018**) DOI: 10.1080/03610470.2018.1469081* available from <https://www.tandfonline.com/doi/full/10.1080/03610470.2018.1469081?scroll=top&needAccess=true>


# load libraries
```{r package.load, results='asis', echo=FALSE, include=FALSE} 
#.rs.restartR()  # restart R 
sessionInfo()

#data wrangling
#install.packages("dplyr")  # dplyr "data plyer"  
library(dplyr)
library(tidyverse)
library(gridExtra)  # for grid.arrange in R markdown

library(caret) # for dummyVars function
library(psych) # for pairs.panels function
library(memisc)  # compare models

```


> flash forward! scroll to the bottom and run bigchunk_tidytransform



#import data
```{r}
rm(list = ls()) # clear workspace
mydata <-read.csv("ujbc_a_1469081_sm5496.txt",stringsAsFactors = FALSE)  ## SPECIFY filename

#dput(names(mydata))

test_df<- mydata # (identical dataframe to be used for testing/illustration)
```


# tidy & transform 

> note: this is a base R +dplyr data wrangling exercise! in general it's best to use lubridate package for date/timestamps! 

* create date column (one at a time)
    * here we're creating new columns in POSIXct format, based on the particular date format used in the source data (ujbc_a_1469081_sm5496.txt; see ?as.POSIXct):
```{r}
x_brew_date.POSIXct<- as.POSIXct(mydata$brew_date, format = "%m/%d/%Y") # as a standalone vector (USELESS here), or:
test_df$brew_date.POSIXct <-as.POSIXct(mydata$brew_date, format = "%m/%d/%Y")  # as a "new column" in our dataframe
```


* ADVANCED data wrangling: 
    * create multiple date columns using FORLOOP
(here we take advantage of the pattern that of our (character) date/time columns have the string "date" in the headername.  First make character vector of all column names containing string "date", then run FORLOOP over each date column).  This forloop will convert datecols into POSIXct format (R/universal datetime format).  In general they say it's  **best to avoid forloops** in general, and **in this case you would probably use functions from lubridate package** - and in general be aware there's probably a specific tool for the task at hand)!!
```{r}
datecols<- dput(names(dplyr::select(mydata, matches("date"))))  ## headers containing string "date" => c("brew_date", "sample_collection_date", "dryhop_date", "Test_Date")
## FORLOOP
for (icol in datecols) {
  newcol = paste0(icol,".POSIXct")
 # print(newcol)
  mydata[, newcol] = as.POSIXct(mydata[, icol],format = "%m/%d/%Y") ###  CREATE NEW columns with POSIXct   
#  mydata[, newcol] = as.POSIXct(as.numeric(mydata[, icol])  * (60*60*24), origin="1899-12-30") ###  microsoft times
}

## create dayofaddition, daysonhops, hops_g_100mL, pounds_bbl variables with dplyr "mutate"
mydata<- mydata %>% 
  mutate(dayofaddition = as.numeric(difftime(dryhop_date.POSIXct,brew_date.POSIXct)),
         daysonhops = as.numeric(difftime(Test_Date.POSIXct,dryhop_date.POSIXct)),
         hops_g_100mL = (mg_hops/volume_mL)/10,
         pounds_bbl = (mg_hops/volume_mL)*117/454
         )
```


* ADVANCED data wrangling: unpack overloaded columns with grepl
```{r}
mydata$OX<-grepl("OX", mydata$Hop_type)       ##  create logical "OX" column
mydata$rouse<-grepl("rouse", mydata$special_group)##  create logical column
mydata$Grind<-grepl("Grind", mydata$Hop_type)     ##  create logical column
mydata$Cone<-grepl("Cone", mydata$Hop_type)       ##  create logical column
mydata$harvest2014<-grepl("14", mydata$Hop_type)  ##  create logical column
mydata$harvest2015<-grepl("15", mydata$Hop_type)  ##  create logical column
mydata$harvest2017<-grepl("17", mydata$Hop_type)  ##  create logical column
```

* ADVANCED data wrangling: ifelse statements for harvestyear, form_of_hops, and DH_temp
```{r}
## ifelse statement for harvestyear (if neither 2014 nor 2015 nor 2017, then 2016)
mydata$harvestYear <- ifelse(
  mydata$harvest2014==TRUE, 2014,
  ifelse(mydata$harvest2015==TRUE, 2015, 
         ifelse(mydata$harvest2017==TRUE, 2017, 2016)))
dput(levels(as.factor(mydata$harvestYear)))
## ifelse statement for form of hops (if neither cone nor ground nor NH, then pellet) 
mydata$form_of_hops <- ifelse(
  mydata$Cone==TRUE, "cone",
  ifelse(mydata$Grind==TRUE, "ground",
         ifelse(mydata$Hop_type=="NH", "NH", "pellet")))
dput(levels(as.factor(mydata$form_of_hops)))
## ifelse statement for temperature greater or less than 10 
mydata$DH_temp <- ifelse(
  mydata$temp.C<10, "cold",
  ifelse(mydata$temp.C>10, "warm", "something else"))
dput(levels(as.factor(mydata$DH_temp)))
```

* ADVANCED data wrangling: create "variety" column starting with overloaded "Hop_type" column, then stripping away all the non-variety information
```{r}
mydata$variety<-mydata$Hop_type
mydata$variety<- gsub("[0-9]+","", mydata$variety) ## remove all numbers
mydata$variety<- gsub("OX","", mydata$variety)     ## remove specific text
mydata$variety<- gsub("Grind","", mydata$variety)
mydata$variety<- gsub("Cone","", mydata$variety)
mydata$variety<- gsub(" ","", mydata$variety)      ## remove spaces
dput(levels(as.factor(mydata$variety)))
```

* ADVANCED data wrangling: create "EXPTnew" (each unique experimental group designated in a single variable)
```{r}
mydata<- mydata %>% mutate(EXPTnew=paste0("group",expt, substr(special_group, 1,2),as.character(rouse)))
# clean it up by removing "NA" and any spaces due to canarycode bug
mydata$EXPTnew <- gsub(" ","", mydata$EXPTnew)  ## remove any spaces
mydata$EXPTnew <- gsub("NA","", mydata$EXPTnew) ## remove "NA"
dput(levels(as.factor(mydata$expt)))
dput(levels(as.factor(mydata$EXPTnew)))
```


## select and rearrange columns 
(experimental factors on the left, then measurements, followed by calculations and then all date columns on the right):
```{r}
mydata <- mydata %>% 
  dplyr::select(sample_id,expt, EXPTnew, hop, BINhop, variety, OX, harvestYear, form_of_hops, rouse, daysonhops, dayofaddition, DH_temp, temp.C, hops_g_100mL, pounds_bbl,
         ABV, ABW, OE, Er, Ea, SG, RDF, ADF, Calories, 
         dhop_day, contact_days, REF_NH, ABV_increase, 
         brew_date.POSIXct, sample_collection_date.POSIXct, dryhop_date.POSIXct,Test_Date.POSIXct)
## remove ".POSIXct" suffix.  Leaving it as-is will only add to confusion if/when these data are saved and re-imported (and become 'character' format!)
colnames(mydata) = gsub(".POSIXct", "", colnames(mydata))
```



##compute mean NH (reference) values 
(NH = not dry-hopped) 
```{r}
## mean NH (control) values for each EXPTnew group
mean.REF_NH<- mydata %>% 
  group_by(EXPTnew) %>%
  filter(hop=="NH") %>%
  summarise_at(vars(ABV, ABW, Ea, SG),funs(mean, n()))
## replace "_mean" with "_NHgroup" in column names
colnames(mean.REF_NH) = gsub("_mean", ".NHgroup", colnames(mean.REF_NH))
```


##compute $\Delta$ values 
* difference of each ABV,ABW,Ea, and SG data point from corresponding mean.REF_NH values (unhopped samples in same EXPTnew group)
```{r}
## using objects created above...
## first join our data with mean ABV for unhopped samples in given experiment (mean.REF_NH; calculated above)

FPHcalc<- left_join(mydata, mean.REF_NH, by="EXPTnew")

## now calculate ABW_increase by subtracting each individual ABW measurement from mean.REF_NH:
FPHcalc$delta.ABV <- FPHcalc$ABV - FPHcalc$ABV.NHgroup
FPHcalc$delta.ABW <- FPHcalc$ABW - FPHcalc$ABW.NHgroup
FPHcalc$delta.plato <- -(FPHcalc$Ea - FPHcalc$Ea.NHgroup)
FPHcalc$delta.SG <- -(FPHcalc$SG - FPHcalc$SG.NHgroup)

## the control samples have served their purpose, now remove them from dataset. The following calculations are only meaningful for dry-hopped samples.  
FPHcalc<- FPHcalc %>% filter(hop=="DH")
```


## *calcalate* corresponding CO2 production 
* following Bamforth (describing Balling equation) "...more realistically, the ethanol yield is more like 0.46 g and carbon dioxide 0.44 g from 1 g sugar"  (p. 137 in Brewing Materials and Processes: A Practical Approach to Beer Excellence, Edited by Charles Bamforth Academic Press, 2016)
```{r}

FPHcalc$calcCO2_increase <- FPHcalc$delta.ABW*(0.44/0.46)
##convert calcCO2_increase (in g/100mL) to calculated CO2 volumes added
## g/L = 10* g/100mL
## The conversion factor from volumes of CO2 to CO2 by weight (g/L) is 1.96. For example: 2.5 volumes x 1.96 = 4.9 g/l.
FPHcalc$calcCO2vols_increase <- FPHcalc$calcCO2_increase*10/1.96

## and define "FPH" as amount produced per % dry-hops added (in g/100mL):
FPHcalc$FPH_EtOH = FPHcalc$delta.ABW/FPHcalc$hops_g_100mL
FPHcalc$FPH_CO2 = FPHcalc$calcCO2_increase/FPHcalc$hops_g_100mL

## and save the transformed data to csv:
write.csv(FPHcalc,"FPHcalc.csv", row.names = FALSE)
FPHcalc <- read.csv("FPHcalc.csv", stringsAsFactors = TRUE)

df<- FPHcalc %>% group_by(EXPTnew) %>%
  summarise_at(vars(hops_g_100mL,pounds_bbl,delta.ABV, delta.ABW,delta.plato, delta.SG, FPH_EtOH, FPH_CO2, calcCO2vols_increase),funs(mean)) %>%
  arrange(desc(FPH_EtOH)) 
df
```






## normalize $\Delta$ values relative to the exact amount of hops added






# visualize
# vector~vector*vector plots
```{r regression.2}
df <-FPHcalc
p1<- ggplot(df, aes(y=FPH_EtOH,x=OE, color=contact_days)) + geom_point(size=2)
p2<- ggplot(df, aes(y=FPH_EtOH,x=ADF, color=contact_days)) + geom_point(size=2)
p3<- ggplot(df, aes(y=FPH_EtOH,x=ABW, color=contact_days)) + geom_point(size=2)
p4<- ggplot(df, aes(y=FPH_EtOH,x=Ea, color=contact_days)) + geom_point(size=2)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```



# x~y*(4 vectors) by color
```{r regression.4plot.color}
df <- FPHcalc
x<- df$Ea
y<- df$FPH_EtOH

p1<- ggplot(df, aes(x,y, color=form_of_hops)) + geom_point(size=2)
p2<- ggplot(df, aes(x,y, color=brew_date)) + geom_point(size=2)
p3<- ggplot(df, aes(x,y, color=rouse)) + geom_point(size=2)
p4<- ggplot(df, aes(x,y, color=pounds_bbl)) + geom_point(size=2)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

#Amunategui "Using Correlations To Understand Your Data"
```{r Amunategui}
mydata<-FPHcalc %>% dplyr::select(expt,variety,form_of_hops,pounds_bbl,rouse,daysonhops,DH_temp,brew_date,ABW,SG,OE,ADF,RDF,calcCO2vols_increase,FPH_CO2, FPH_EtOH)  ## last one is 100% in j

## note use of "dplyr::select" because one of these packages is conflicting with dplyr commands :()

## following  Manuel Amunategui  https://www.youtube.com/watch?v=igPQ-pI8Bjo
## Using Correlations To Understand Your Data: Machine Learning With R 
##functions for flattenSquareMatrix
cor.prob <- function (X, dfr=nrow(X) -2) {
  R<- cor(X, use="pairwise.complete.obs")
  above<- row(R) < col(R)
  r2 <- R[above]^2
  Fstat<- r2 * dfr/(1-r2)
  R[above] <- 1- pf(Fstat, 1, dfr)
  R[row(R) == col(R)] <- NA
  R
}
flattenSquareMatrix <- function(m) {
  if( (class(m) != "matrix") | (nrow(m)!=ncol(m))) stop("Must be a square matrix.")
  if(!identical(rownames(m), colnames(m))) stop("Row and column names must be equal.")
  ut <- upper.tri(m)
  data.frame(i = rownames(m)[row(m)[ut]],
             j = rownames(m)[col(m)[ut]],
             cor=t(m)[ut],
             p=m[ut])
}

## library(caret) to dummify everything (turn all characters&factors into columns;  ignores numbers and integers)
dmy<- dummyVars(" ~ .",data = mydata)
mydummifieddata<- data.frame(predict(dmy, newdata = mydata))
corMat = cor(mydummifieddata)
corMasterList<- flattenSquareMatrix(cor.prob(mydummifieddata)) ## list of all correlations
## order by strength of correlation
corlist<- corMasterList %>% arrange(-abs(corMasterList$cor)) 
write.csv(corlist,paste0("FLAT correlation matrix_.csv"))
corlist <- corlist %>% dplyr::filter(j=="FPH_EtOH")   ## filter specific endpoint
head(corlist,50)
```

# pairs.panels correlation matrix from library(psych)
```{r}
## specify interesting variables:  
interestingvariables<-c("ABW", "pounds_bbl", "daysonhops", "calcCO2vols_increase") 
pairs.panels(mydummifieddata[c(interestingvariables, "FPH_EtOH")])
```

#modeling Overview
Observing the impacts of dryhopping in the presence of live yeast has led many brewing professionals to understand that FPH is a function of many of the variables above including hop variety,form_of_hops,harvestYear,OX,DH_temp,daysonhops,rouse,pounds_bbl.... Many have intuitively created a model in their heads (without necessarily thinking of it as such) and skillfully adjust process when necessary to account for this phenomenon.  In linear modeling, our function will take on the form:
$FPH =  intercept + \beta_{1}X_{1} + \beta_{2}X_{2} + ... + \beta_{n}X_{n}$ where $\beta$ values are what we're attempting to derive in this modeling exercise, and X values are (collectively) a particular set of conditions.

>> ActionItem:  add link to modeling overview




# linear models 1 (create models)
```{r}
df<-FPHcalc

lm1<-lm(df$SG~df$OE)
lm2<-lm(df$SG~df$ADF)
lm3<-lm(df$SG~df$ABW)
lm4<-lm(df$SG~df$Ea)
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(df$SG~df$OE)
abline(lm1)
plot(df$SG~df$ADF)
abline(lm2)
plot(df$SG~df$ABW)
abline(lm3)
plot(df$SG~df$Ea)
abline(lm4)
```

# linear models 2 (view residual plots)
```{r}
df<-FPHcalc

lm1<-lm(df$SG~df$OE)
lm2<-lm(df$SG~df$ADF)
lm3<-lm(df$SG~df$ABW)
lm4<-lm(df$SG~df$Ea)

par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(lm1$residuals)
plot(lm2$residuals)
plot(lm3$residuals)
plot(lm4$residuals)
#summary(lm4)
```


# compare linear models 
```{r}
df<-FPHcalc

lm1<-lm(df$SG~df$OE)
lm2<-lm(df$SG~df$ADF)
lm3<-lm(df$SG~df$ABW)
lm4<-lm(df$SG~df$Ea)

mtable1234 <- mtable("Model 1"=lm1,"Model 2"=lm2,"Model 3"=lm3, "Model 4"=lm4,
                    summary.stats=c("sigma","R-squared","F","p","N"),show.eqnames=T)

mtable1234b <- relabel(mtable1234,
                      "(Intercept)" = "Constant",
                      x1 = "OE = Original Extract (g/100mL)",
                      x2 = "ADF = Apparent Degree of Fermentation (%)",
                      x3 = "ABW = Ethanol (w/w)",
                      x4 = "Er = Residual Extract (g/100mL)"
                      )
mtable1234
#show_html(mtable1234b)
```





# compare linear models
```{r}
df <- FPHcalc
lm1<-lm(FPH_EtOH~daysonhops, data=df)
lm2<-lm(FPH_EtOH~daysonhops*form_of_hops, data=df)
lm3<-lm(FPH_EtOH~daysonhops*rouse, data=df)
lm4<-lm(FPH_EtOH~daysonhops*form_of_hops*rouse, data=df)

mtable1234 <- mtable("Model 1"=lm1,"Model 2"=lm2,"Model 3"=lm3, "Model 4"=lm4,
                    summary.stats=c("sigma","R-squared","F","p","N"),show.eqnames=T)
mtable1234b <- relabel(mtable1234,
                      "(Intercept)" = "Constant",
                      SG = "Specific Gravity",
                      ABW = "ABW = Ethanol (w/w)",
                      Er = "Er = Residual Extract (g/100mL)"
                      )
mtable1234
#show_html(mtable1234b)
```



#The R Book (Crawley) Table 20.1: nonlinear functions useful in biology   
Table 20.1. [Useful non-linear functions](https://www.cs.upc.edu/~robert/teaching/estadistica/TheRBook.pdf "Michael J. Crawley.  The R book.  p. 738") EXPANDED:



| Function Class | name | equation | example code |example applications|
|:----------|:-----:|:-------|:-----|:-----|
| **Asymptotic functions**|Michaelis–Menten|$y =\frac{ax}{1+bx}$|nls(bone~a*age/(1+b*age),start=list(a=8,b=0.08))) | enzyme reactions |
| | | | nls(rate~SSmicmen(conc,a,b)) | tbd|
| |2-parameter asymptotic exponential | $y = a(1 − e^{−bx} )$ |nls(bone~a*(1-exp(-c*age)),start=list(a=120,c=0.064)) | tbd |
| |3-parameter asymptotic exponential | $y = a − be^{−cx}$ | nls(bone~a-b*exp(-c*age),start=list(a=120,b=110,c=0.064)) | tbd |
| | | | nls(bone~SSasymp(age,a,b,c)) | tbd |
| | | | nls(density ~ SSlogis(log(concentration), a, b, c)) | tbd |
|**S-shaped functions** |2-parameter logistic |$y = \frac{e^{a+bx}}{1 + e^{a+bx}}$ | | tbd |
| | 3-parameter logistic | $y = \frac{a}{1 + be^{−cx}}$ | | tbd |
| | 4-parameter logistic | $y = a + \frac{b-a}{1 + e^{(c−x)/d}}$ | nls(weight~SSfpl(Time, a, b, c, d)) | tbd |
| | Weibull | $y = a − be^{−(cx^d)}$ | nls(weight ~ SSweibull(time, Asym, Drop, lrc, pwr)) | tbd |
| | Gompertz | $y = ae^{−be^{−cx}}$ | | tbd |
| **Humped curves** | Ricker curve | $y = axe^{−bx}$ | | tbd |
| | First-order compartment | $y = k exp(−exp(a)x) − exp(−exp(b)x)$ | nls(conc~SSfol(Dose, Time, a, b, c)) | tbd |
| | Bell-shaped | $y = a exp(−ABS(bx)^2)$ | | tbd |
| | Biexponential | $y = ae^{bx} − ce^{−dx}$  | | tbd |





# bigchunk_tidytransform
```{r chunk_tidytransform, echo=FALSE}
rm(list = ls()) # clear workspace
mydata <-read.csv("ujbc_a_1469081_sm5496.txt",stringsAsFactors = FALSE)  ## SPECIFY filename

## create new variables (*.POSIXct, dayofaddition, daysonhops, hops_g_100mL, pounds_bbl, variety, harvestyear,ox)
### note: this is a base R data wrangling exercise! in general it's best to use lubridate package for date/timestamps! 

## can do one at a time (here we're creating new columns in POSIXct format, based on the particular date format used in the source data (ujbc_a_1469081_sm5496.txt; see ?as.POSIXct):
#x_brew_date.POSIXct<- as.POSIXct(mydata$brew_date, format = "%m/%d/%Y") # as a standalone vector (USELESS here), or:
#mydata$brew_date.POSIXct <-as.POSIXct(mydata$brew_date, format = "%m/%d/%Y")  # as a "new column" in our dataframe
  
## or, we can take advantage of the pattern that of our (character) date/time columns have the string "date" in the headername.  First make character vector of all column names containing string "date":
#datecols<- dput(names(select(mydata, matches("date"))))  ## headers containing string "date"

#dput(names(mydata))

datecols<- c("brew_date", "sample_collection_date", "dryhop_date", "Test_Date")
## FORLOOP
# this forloop will (attempt to) convert datecols (define above) into POSIXct format (R datetime format).  In general they say it's  ### best to avoid forloops ### use functions from lubridate/etc packages with specific tools for the task at hand)!! ###
for (icol in datecols) {
  newcol = paste0(icol,".POSIXct")
 # print(newcol)
  mydata[, newcol] = as.POSIXct(mydata[, icol],format = "%m/%d/%Y") ###  CREATE NEW columns with POSIXct   
#  mydata[, newcol] = as.POSIXct(as.numeric(mydata[, icol])  * (60*60*24), origin="1899-12-30") ###  microsoft times
}

## create dayofaddition, daysonhops, hops_g_100mL, pounds_bbl variables with dplyr "mutate"
mydata<- mydata %>% 
  mutate(dayofaddition = as.numeric(difftime(dryhop_date.POSIXct,brew_date.POSIXct)),
         daysonhops = as.numeric(difftime(Test_Date.POSIXct,dryhop_date.POSIXct)),
         hops_g_100mL = (mg_hops/volume_mL)/10,
         pounds_bbl = (mg_hops/volume_mL)*117/454
         )

mydata$OX<-grepl("OX", mydata$Hop_type)           ##  create logical "OX" column
mydata$rouse<-grepl("rouse", mydata$special_group)##  create logical "rouse" column
mydata$Grind<-grepl("Grind", mydata$Hop_type)     ##  create logical column
mydata$Cone<-grepl("Cone", mydata$Hop_type)       ##  create logical column
mydata$harvest2014<-grepl("14", mydata$Hop_type)  ##  create logical column
mydata$harvest2015<-grepl("15", mydata$Hop_type)  ##  create logical column
mydata$harvest2017<-grepl("17", mydata$Hop_type)  ##  create logical column
## ifelse statement for harvestyear (if neither 2014 nor 2015 nor 2017, then 2016)
mydata$harvestYear <- ifelse(
  mydata$harvest2014==TRUE, 2014,
  ifelse(mydata$harvest2015==TRUE, 2015, 
         ifelse(mydata$harvest2017==TRUE, 2017, 2016)))
## ifelse statement for form of hops (if neither cone nor ground nor NH, then pellet) 
mydata$form_of_hops <- ifelse(
  mydata$Cone==TRUE, "cone",
  ifelse(mydata$Grind==TRUE, "ground",
         ifelse(mydata$Hop_type=="NH", "NH", "pellet")))

## ifelse statement for temperature greater or less than 10 
mydata$DH_temp <- ifelse(
  mydata$temp.C<10, "cold",
  ifelse(mydata$temp.C>10, "warm", "something else"))

## create "variety" column starting with "Hop_type" then stripping away all the non-variety information
mydata$variety<-mydata$Hop_type
mydata$variety<- gsub("17","", mydata$variety)
mydata$variety<- gsub("16","", mydata$variety)
mydata$variety<- gsub("15","", mydata$variety)
mydata$variety<- gsub("14","", mydata$variety)
mydata$variety<- gsub("OX","", mydata$variety)
mydata$variety<- gsub("Grind","", mydata$variety)
mydata$variety<- gsub("Cone","", mydata$variety)
mydata$variety<- gsub(" ","", mydata$variety)

## create "EXPTnew" (each unique experimental group designated in a single column)
mydata<- mydata %>% mutate(EXPTnew=paste0("group",expt, substr(special_group, 1,2),as.character(rouse)))
# clean it up by removing "NA" and any spaces due to canarycode bug
mydata$EXPTnew <- gsub(" ","", mydata$EXPTnew)  ## remove any spaces
mydata$EXPTnew <- gsub("NA","", mydata$EXPTnew) ## remove "NA"

## rearrange columns (experimental factors on the left, then measurements, followed by calculations and finally all the date columns on the right):
mydata <- mydata %>% 
  dplyr::select(sample_id,expt, EXPTnew, hop, BINhop, variety, OX, harvestYear, form_of_hops, rouse, daysonhops, dayofaddition, DH_temp, temp.C, hops_g_100mL, pounds_bbl,
         ABV, ABW, OE, Er, Ea, SG, RDF, ADF, Calories, 
         dhop_day, contact_days, REF_NH, ABV_increase, 
         brew_date.POSIXct, sample_collection_date.POSIXct, dryhop_date.POSIXct,Test_Date.POSIXct)
## remove ".POSIXct" suffix.  Leaving it as-is will only add to confusion if/when these data are saved and re-imported (and become 'character' format!)
colnames(mydata) = gsub(".POSIXct", "", colnames(mydata))
















#compute baseline ABW for each EXPTnew group
meanABW.REF_NH<- mydata %>% 
  group_by(EXPTnew) %>%
  filter(hop=="NH") %>%
  summarise(ABW.REF_NH=mean(ABW))

## compute mean increase in ABW relative to meanABW.REF_NH (unhopped samples in same EXPTnew group), and normalize this relative to the exact amount of hops added
## using objects created above...
## first join our data with mean ABV for unhopped samples in given experiment (meanABW.REF_NH; calculated above)

FPHcalc<- left_join(mydata, meanABW.REF_NH, by="EXPTnew")

## now calculate ABW_increase by subtracting each individual ABW measurement from meanABW.REF_NH:
FPHcalc$ABW_increase <- FPHcalc$ABW - FPHcalc$ABW.REF_NH

## the control samples have served their purpose, now remove them from dataset. The following calculations are only meaningful for dry-hopped samples.  
FPHcalc<- FPHcalc %>% filter(hop=="DH")


## compute corresponding CO2 production following Bamforth (describing Balling equation) "...more realistically, the ethanol yield is more like 0.46 g and carbon dioxide 0.44 g from 1 g sugar"  (p. 137 in Brewing Materials and Processes: A Practical Approach to Beer Excellence, Edited by Charles Bamforth Academic Press, 2016)
FPHcalc$calcCO2_increase <- FPHcalc$ABW_increase*(0.44/0.46)
##convert calcCO2_increase (in g/100mL) to calculated CO2 volumes added
## g/L = 10* g/100mL
## The conversion factor from volumes of CO2 to CO2 by weight (g/L) is 1.96. For example: 2.5 volumes x 1.96 = 4.9 g/l.
FPHcalc$calcCO2vols_increase <- FPHcalc$calcCO2_increase*10/1.96

## and define "FPH" as amount produced per % dry-hops added (in g/100mL):
FPHcalc$FPH_EtOH = FPHcalc$ABW_increase/FPHcalc$hops_g_100mL
FPHcalc$FPH_CO2 = FPHcalc$calcCO2_increase/FPHcalc$hops_g_100mL

## and save the transformed data to csv:
write.csv(FPHcalc,"FPHcalc.csv", row.names = FALSE)
FPHcalc <- read.csv("FPHcalc.csv", stringsAsFactors = TRUE)

df<- FPHcalc %>% group_by(EXPTnew) %>%
  summarise_at(vars(hops_g_100mL,pounds_bbl, ABW_increase,FPH_EtOH, FPH_CO2, calcCO2vols_increase),funs(mean)) %>%
  arrange(desc(FPH_EtOH)) 
df
```



```{r}
sessionInfo()
```

